{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.model import DeepCleanAutoencoder\n",
    "from src.dataset import GWDataset\n",
    "from src.utils import postprocess\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f390c0",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ad670",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/best_model.pth'\n",
    "TEST_DATA_PATH = 'data/test_data.npz' \n",
    "\n",
    "# match training\n",
    "SAMPLE_RATE = 2048 \n",
    "BAND_MIN = 55.0\n",
    "BAND_MAX = 65.0\n",
    "\n",
    "INFERENCE_OVERLAP = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec577e4",
   "metadata": {},
   "source": [
    "### Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(TEST_DATA_PATH)\n",
    "strain_raw = data['strain']\n",
    "witnesses_raw = data['witnesses']\n",
    "\n",
    "print(f\"Strain Shape: {strain_raw.shape}\")\n",
    "print(f\"Witnesses Shape: {witnesses_raw.shape}\")\n",
    "\n",
    "test_dataset = GWDataset(\n",
    "    strain_raw, \n",
    "    witnesses_raw, \n",
    "    SAMPLE_RATE, \n",
    "    overlap=INFERENCE_OVERLAP, \n",
    "    band_start=BAND_MIN, \n",
    "    band_end=BAND_MAX\n",
    ")\n",
    "\n",
    "model = DeepCleanAutoencoder(num_witnesses=witnesses_raw.shape[0]).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bea9b",
   "metadata": {},
   "source": [
    "### Run Inference + post process stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_idx = 0\n",
    "\n",
    "w_tensor, h_tensor_norm = test_dataset[segment_idx]\n",
    "\n",
    "w_batch = w_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_normalized = model(w_batch)\n",
    "\n",
    "noise_estimate = postprocess(\n",
    "    pred_normalized, \n",
    "    test_dataset.strain_mean, \n",
    "    test_dataset.strain_std, \n",
    "    SAMPLE_RATE, \n",
    "    BAND_MIN, \n",
    "    BAND_MAX\n",
    ")\n",
    "\n",
    "start_idx = test_dataset.indices[segment_idx]\n",
    "end_idx = start_idx + test_dataset.seg_len\n",
    "\n",
    "segment_original = strain_raw[start_idx:end_idx]\n",
    "segment_cleaned = segment_original - noise_estimate\n",
    "\n",
    "print(f\"Processed Segment {segment_idx} (Time: {start_idx/SAMPLE_RATE:.1f}s - {end_idx/SAMPLE_RATE:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ab5f0",
   "metadata": {},
   "source": [
    "### Actual visualization stuff i dont feel like doing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
